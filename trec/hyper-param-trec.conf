[hparam]
data = data/trec_data/raw_data/train_6_all_2017_06_08.pt
pre_word_vecs = data/trec_data/raw_data/wv_all_2017_06_08.npz
save_model = trec/data/
log = trec/log/
interval = 50

classes = 6


## Shared Memory
word_vec_size = 300
mem_size = 300
# LSTM
lstm = False
layer = 1
brnn = False
# CNN
kernel_size = 1,2,3
use_batch_norm = True


## Attention subnet
layer_c = 1
rnn_size_c = 300
hop = 2


# hyper-parameters
temp = 1.0
alpha = 0.9
beta = 3
enpy = 0.5


## Optimizition
batch_size = 16
epochs = 30
start_epoch = 1
param_init = 0.1
# rmsprop, sgd, adagrad, adadelta, adam, rmsprop
optim = rmsprop
max_grad_norm = 0.05
learning_rate = 0.0005

learning_rate_decay = 1
start_decay_at = 100

dropout = 0.5
extra_shuffle = False
weight_decay = 0


# visualize with tensorboardX
visualize = False










